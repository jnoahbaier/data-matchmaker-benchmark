{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2c7b9308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76a7839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d636c7",
   "metadata": {},
   "source": [
    "### Get Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b81de4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(DATAFRAME_SAMPLE_JSON):\n",
    "    return \"\"\"You are helping author STATIC benchmark tasks for a schema-alignment evaluation.\n",
    "\n",
    "The goal is to transform ONE input dataframe into multiple fragmented, CSV-like tables\n",
    "that simulate exports from different organizational systems.\n",
    "\n",
    "The solver (purple agent) will be given ONLY the fragmented tables and must infer:\n",
    "1) primary keys\n",
    "2) join relationships\n",
    "3) naming inconsistencies\n",
    "4) a merged canonical schema\n",
    "\n",
    "CRITICAL RULES (MUST FOLLOW EXACTLY):\n",
    "\n",
    "A) VALUE PRESERVATION (NON-NEGOTIABLE)\n",
    "- You are given ONE input dataframe.\n",
    "- You MUST NOT change any cell values.\n",
    "- You may ONLY:\n",
    "  1) split the dataframe into multiple tables (column subsets)\n",
    "  2) optionally subset rows (preserve exact values)\n",
    "  3) reorder rows or columns\n",
    "  4) rename columns\n",
    "  5) rename tables\n",
    "  6) drop columns\n",
    "- You MUST NOT:\n",
    "  - edit numbers, strings, dates, or IDs\n",
    "  - normalize, clean, impute, or synthesize values\n",
    "  - invent new identifiers or relationships\n",
    "\n",
    "B) ROW TRACEABILITY\n",
    "- Every output table MUST include a shared row identifier column copied from the input\n",
    "  (e.g., \"__row_id__\" or an existing unique ID).\n",
    "- Do NOT rename this row identifier.\n",
    "\n",
    "C) TABLE NAMING (COLUMN-DRIVEN, REQUIRED)\n",
    "- Table names MUST be inferred ONLY from their column content.\n",
    "- Use short, lowercase, plural nouns.\n",
    "- Examples:\n",
    "  - (customer_id, customer_name, email) → \"customers\"\n",
    "  - (order_id, order_date, amount) → \"orders\"\n",
    "- Do NOT use generic or theme-based names.\n",
    "\n",
    "D) DIFFICULTY DEFINITIONS\n",
    "You MUST generate THREE tasks with increasing difficulty:\n",
    "\n",
    "1) Easy task:\n",
    "   - exactly 2 tables\n",
    "   - obvious primary keys\n",
    "   - exactly ONE simple naming inconsistency\n",
    "     (e.g., case or underscore difference)\n",
    "\n",
    "2) Medium task:\n",
    "   - exactly 3 tables\n",
    "   - mixed naming conventions\n",
    "     (snake_case, camelCase, UPPER_CASE)\n",
    "   - at least 2 join relationships\n",
    "\n",
    "3) Hard task:\n",
    "   - exactly 5 tables\n",
    "   - complex relationship graph\n",
    "   - ambiguous column names (e.g., \"id\", \"department\")\n",
    "   - at least one of:\n",
    "     * self-referential join\n",
    "     * multi-hop join chain (A → B → C)\n",
    "\n",
    "E) JOIN REALISM\n",
    "- If ground_truth includes a join [\"A.colX\",\"B.colY\"],\n",
    "  then the values in those columns MUST overlap in the sample rows shown.\n",
    "\n",
    "F) OUTPUT FORMAT\n",
    "- Output ONLY valid JSON.\n",
    "- No markdown, no comments, no explanations.\n",
    "\n",
    "---\n",
    "\n",
    "## OUTPUT FORMAT (MUST MATCH EXACTLY)\n",
    "\n",
    "Return a JSON ARRAY of SIX objects, in this order:\n",
    "1) easy task #1\n",
    "2) easy task #2\n",
    "3) medium task #1\n",
    "4) medium task #2\n",
    "5) hard task #1\n",
    "6) hard task #2\n",
    "Each object MUST follow this schema:\n",
    "\n",
    "{\n",
    "  \"task_id\": \"string\",\n",
    "  \"difficulty\": \"easy | medium | hard\",\n",
    "  \"source\": {\n",
    "    \"input_name\": \"string\",\n",
    "    \"row_id_col\": \"string\"\n",
    "  },\n",
    "  \"tables\": [\n",
    "    {\n",
    "      \"name\": \"string\",\n",
    "      \"columns\": [\"string\", \"...\"],\n",
    "      \"sample_data\": [\n",
    "        {\"column\": \"value\", \"...\": \"...\"},\n",
    "        {\"column\": \"value\", \"...\": \"...\"}\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"provenance\": {\n",
    "    \"table_name\": {\n",
    "      \"output_column\": \"input_column\"\n",
    "    }\n",
    "  },\n",
    "  \"ground_truth\": {\n",
    "    \"primary_keys\": {\"table\": \"column\"},\n",
    "    \"join_columns\": [[\"table.col\",\"table.col\"]],\n",
    "    \"inconsistencies\": [\"string\"],\n",
    "    \"merged_schema\": {\n",
    "      \"unified_table_name\": [\"canonical_col\", \"...\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "NOTES:\n",
    "- sample_data rows must include ALL listed columns.\n",
    "- primary key columns must be unique in the sample rows.\n",
    "- merged_schema column names should be canonicalized (snake_case preferred).\n",
    "- provenance must cover EVERY output column in EVERY table.\n",
    "\n",
    "---\n",
    "\n",
    "## INPUT DATAFRAME (DO NOT CHANGE VALUES)\"\"\"+f\"\"\"\n",
    "\n",
    "{DATAFRAME_SAMPLE_JSON}\n",
    "\n",
    "---\n",
    "\"\"\" + \"\"\"\n",
    "\n",
    "## FEW-SHOT EXAMPLE (EASY ONLY)\n",
    "\n",
    "{\n",
    "  \"task_id\": \"easy_customers_orders\",\n",
    "  \"difficulty\": \"easy\",\n",
    "  \"source\": {\n",
    "    \"input_name\": \"input.csv\",\n",
    "    \"row_id_col\": \"__row_id__\"\n",
    "  },\n",
    "  \"tables\": [\n",
    "    {\n",
    "      \"name\": \"customers\",\n",
    "      \"columns\": [\"__row_id__\", \"cust_id\", \"customer_name\", \"email\"],\n",
    "      \"sample_data\": [\n",
    "        {\"__row_id__\": 0, \"cust_id\": 1, \"customer_name\": \"Alice\", \"email\": \"alice@example.com\"},\n",
    "        {\"__row_id__\": 1, \"cust_id\": 2, \"customer_name\": \"Bob\", \"email\": \"bob@example.com\"}\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"orders\",\n",
    "      \"columns\": [\"__row_id__\", \"order_id\", \"customer_ID\", \"amount\"],\n",
    "      \"sample_data\": [\n",
    "        {\"__row_id__\": 0, \"order_id\": 101, \"customer_ID\": 1, \"amount\": 99.99},\n",
    "        {\"__row_id__\": 1, \"order_id\": 102, \"customer_ID\": 2, \"amount\": 149.50}\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"provenance\": {\n",
    "    \"customers\": {\n",
    "      \"__row_id__\": \"__row_id__\",\n",
    "      \"cust_id\": \"customer_id\",\n",
    "      \"customer_name\": \"customer_name\",\n",
    "      \"email\": \"email\"\n",
    "    },\n",
    "    \"orders\": {\n",
    "      \"__row_id__\": \"__row_id__\",\n",
    "      \"order_id\": \"order_id\",\n",
    "      \"customer_ID\": \"customer_id\",\n",
    "      \"amount\": \"amount\"\n",
    "    }\n",
    "  },\n",
    "  \"ground_truth\": {\n",
    "    \"primary_keys\": {\n",
    "      \"customers\": \"cust_id\",\n",
    "      \"orders\": \"order_id\"\n",
    "    },\n",
    "    \"join_columns\": [\n",
    "      [\"customers.cust_id\", \"orders.customer_ID\"]\n",
    "    ],\n",
    "    \"inconsistencies\": [\n",
    "      \"cust_id vs customer_ID (case and naming)\"\n",
    "    ],\n",
    "    \"merged_schema\": {\n",
    "      \"customer_orders\": [\n",
    "        \"customer_id\",\n",
    "        \"customer_name\",\n",
    "        \"email\",\n",
    "        \"order_id\",\n",
    "        \"amount\"\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "---\n",
    "\n",
    "## YOUR TASK\n",
    "\n",
    "Using the SAME input dataframe:\n",
    "- Generate SIX tasks:\n",
    "  1) two EASY\n",
    "  2) two MEDIUM\n",
    "  3) two HARD\n",
    "- Tasks of the same difficulty MUST differ in table splits, naming, or joins.\n",
    "- Follow ALL rules above.\n",
    "- Return ONLY a JSON ARRAY of six task objects.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0374971c",
   "metadata": {},
   "source": [
    "### Run Single Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1262a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_response_gpt(prompt):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1\",   # fast + cheap + good with tables\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a careful data reasoning assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7331059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_response(DATAFRAME_SAMPLE_JSON):\n",
    "    prompt = get_prompt(DATAFRAME_SAMPLE_JSON)\n",
    "    result = get_single_response_gpt(prompt)\n",
    "\n",
    "    return result, prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c453386",
   "metadata": {},
   "source": [
    "### Run On One Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a69c86ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"CRM-Data-Analysis-With-Python.xlsx\")\n",
    "output_dir = \"tasks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dad28d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_df = df[:5]\n",
    "\n",
    "curr_df  = curr_df[curr_df.columns[:10]]\n",
    "\n",
    "json_data = json.dumps(\n",
    "    {\"name\": \"source\", \"columns\": list(curr_df.columns), \"sample_data\": curr_df.to_dict(orient=\"records\")},\n",
    ")\n",
    "result, prompt = get_single_response(json_data)\n",
    "parsed_results = json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "76f6a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_task_number(root_dir, difficulty):\n",
    "    pattern = re.compile(rf\"^task_{re.escape(difficulty)}_(\\d+)$\")\n",
    "    max_number = -1\n",
    "\n",
    "    for p in Path(root_dir).iterdir():\n",
    "        if p.is_dir():\n",
    "            match = pattern.match(p.name)\n",
    "            if match:\n",
    "                num = int(match.group(1))\n",
    "                max_number = num if max_number is None else max(max_number, num)\n",
    "\n",
    "    return max_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1480df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_one_task(task_dir, task_dict):\n",
    "    difficulty = task_dict['difficulty']\n",
    "    folder_name = f\"task_{difficulty}_{find_max_task_number(task_dir, difficulty)+1}\"\n",
    "\n",
    "    save_dir = os.path.join(task_dir, folder_name)\n",
    "    os.makedirs(save_dir, exist_ok=False)\n",
    "\n",
    "    # save all the tables\n",
    "    for table in task_dict['tables']:\n",
    "       data_dict = {x:[] for x in table['columns']} \n",
    "\n",
    "       for row in table['sample_data']:\n",
    "           for key, val in row.items():\n",
    "               data_dict[key].append(val)\n",
    "       \n",
    "       data_df = pd.DataFrame(data_dict)\n",
    "\n",
    "       data_df.to_csv(os.path.join(save_dir, table['name']+\".csv\"), index=False, encoding=\"utf-8\")\n",
    "\n",
    "    # save the ground truth as json file\n",
    "    with open(os.path.join(save_dir, \"ground_truth.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(task_dict['ground_truth'], f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4007ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in parsed_results:\n",
    "    save_one_task(output_dir, task)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alibi-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
